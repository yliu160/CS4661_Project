{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f845c03-31fb-4764-9f86-e2e601aecefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression  # For Linear Regression\n",
    "from sklearn import metrics  # To evaluate the model\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder  # For scaling and encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a13818d1-5551-4ff0-a345-fe3cb2c5abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and testing datasets\n",
    "df_train = pd.read_csv('fraudTrain.csv')\n",
    "df_test = pd.read_csv('fraudTest.csv')\n",
    "\n",
    "# Add source column to distinguish datasets during preprocessing\n",
    "df_train['source'] = 'train'\n",
    "df_test['source'] = 'test'\n",
    "\n",
    "# Combine datasets for consistent preprocessing\n",
    "df = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f6f30ab-2118-4fa1-8f57-8e797870a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df.drop(['Unnamed: 0', 'unix_time', 'trans_num'], axis=1, inplace=True)\n",
    "\n",
    "# Handle 'dob' and calculate 'age'\n",
    "if 'dob' in df.columns:\n",
    "    from datetime import datetime\n",
    "    df['dob'] = pd.to_datetime(df['dob'], errors='coerce')\n",
    "    current_year = datetime.now().year\n",
    "    df['age'] = current_year - df['dob'].dt.year\n",
    "    df.drop(columns=['dob'], inplace=True)\n",
    "else:\n",
    "    print(\"Warning: 'dob' column not found in the dataset!\")\n",
    "    df['age'] = 40  # Placeholder if 'dob' or 'age' is missing\n",
    "\n",
    "# Encode 'gender' column as binary\n",
    "df['gender'] = df['gender'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "\n",
    "# One-hot encode columns with few categories\n",
    "df = pd.get_dummies(df, columns=['state', 'category'], drop_first=True)\n",
    "\n",
    "# Label encode columns with many unique values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "for col in ['merchant', 'first', 'last', 'street', 'city', 'job']:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Feature engineering: Add interaction features or create bins\n",
    "df['age_gender_interaction'] = df['age'] * df['gender']\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 25, 40, 60, 100], labels=['<25', '25-40', '40-60', '60+'])\n",
    "df = pd.get_dummies(df, columns=['age_group'], drop_first=True)\n",
    "\n",
    "# Split the combined dataset back into training and testing datasets\n",
    "df_train = df[df['source'] == 'train'].drop(columns=['source'])\n",
    "df_test = df[df['source'] == 'test'].drop(columns=['source'])\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X_train = df_train.drop(columns=['is_fraud'])\n",
    "y_train = df_train['is_fraud']\n",
    "X_test = df_test.drop(columns=['is_fraud'])\n",
    "y_test = df_test['is_fraud']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "584ac9ba-a569-4447-9f55-8ded82f33b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling, data types:\n",
      "trans_date_trans_time      object\n",
      "cc_num                      int64\n",
      "merchant                    int64\n",
      "amt                       float64\n",
      "first                       int64\n",
      "                           ...   \n",
      "category_travel              bool\n",
      "age_gender_interaction      int64\n",
      "age_group_25-40              bool\n",
      "age_group_40-60              bool\n",
      "age_group_60+                bool\n",
      "Length: 84, dtype: object\n",
      "After preprocessing, data types:\n",
      "cc_num               int64\n",
      "merchant             int64\n",
      "amt                float64\n",
      "first                int64\n",
      "last                 int64\n",
      "                    ...   \n",
      "age_group_25-40       bool\n",
      "age_group_40-60       bool\n",
      "age_group_60+         bool\n",
      "year                 int32\n",
      "month                int32\n",
      "Length: 85, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types before scaling\n",
    "print(\"Before scaling, data types:\")\n",
    "print(X_train.dtypes)\n",
    "\n",
    "# Handle datetime column if it exists\n",
    "if 'trans_date_trans_time' in X_train.columns:\n",
    "    X_train['year'] = pd.to_datetime(X_train['trans_date_trans_time']).dt.year\n",
    "    X_train['month'] = pd.to_datetime(X_train['trans_date_trans_time']).dt.month\n",
    "    X_train.drop(columns=['trans_date_trans_time'], inplace=True)\n",
    "    X_test['year'] = pd.to_datetime(X_test['trans_date_trans_time']).dt.year\n",
    "    X_test['month'] = pd.to_datetime(X_test['trans_date_trans_time']).dt.month\n",
    "    X_test.drop(columns=['trans_date_trans_time'], inplace=True)\n",
    "\n",
    "# Encode categorical columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "for col in X_train.select_dtypes(include=['object']).columns:\n",
    "    X_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "    X_test[col] = label_encoder.transform(X_test[col])\n",
    "\n",
    "# Check data types again\n",
    "print(\"After preprocessing, data types:\")\n",
    "print(X_train.dtypes)\n",
    "\n",
    "# Standardize features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48983b6c-173d-4d71-8c78-20f42cd10628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11c043ec-8400-4c5b-9a42-0c003c84b366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.003736869382023784\n",
      "R-squared: 0.02811377161426476\n"
     ]
    }
   ],
   "source": [
    "# Train the Linear Regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_predictions = linear_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = metrics.mean_squared_error(y_test, y_test_predictions)\n",
    "r_squared = metrics.r2_score(y_test, y_test_predictions)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R-squared:\", r_squared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8123be1-ecce-4ab8-900f-dd6f3e395205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Results and Observations\n",
    "\n",
    "# The Linear Regression model was applied to predict the 'is_fraud' target variable.\n",
    "# Results:\n",
    "# - Mean Squared Error (MSE): 0.003736869382023784\n",
    "# - R-squared: 0.02811377161426476\n",
    "\n",
    "# Observations:\n",
    "# 1. The R-squared value (~2.81%) indicates that the model explains only a small portion of the variance.\n",
    "# 2. This result is expected because fraud detection often involves non-linear relationships \n",
    "#    that Linear Regression cannot capture effectively.\n",
    "# 3. The dataset might have imbalanced classes (fewer fraudulent transactions), making it \n",
    "#    harder for the Linear Regression model to generalize.\n",
    "\n",
    "# Recommendations:\n",
    "# - Use this model as a baseline to compare with other advanced algorithms.\n",
    "# - Consider using non-linear models like Random Forest or Logistic Regression \n",
    "#   for better performance in future tasks.\n",
    "# - Address class imbalance using techniques like SMOTE for improved learning.\n",
    "# - Perform feature selection or engineering to identify stronger predictors of fraud.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9190369-506e-4e31-bcb2-8a0f53562c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
